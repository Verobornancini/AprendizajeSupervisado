{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h4>Universidad Nacional de Córdoba - Facultad de Matemática, Astronomía, Física y Computación</h4>\n",
    "<h3>Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Aprendizaje Supervisado -> Grupo 5 Cohorte 2</h1>\n",
    "\n",
    "Patricia Loto\n",
    "\n",
    "Sandra Monica Olariaga\n",
    "\n",
    "Veronica Bornancini\n",
    "\n",
    "Fernandez María Soledad   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diplodatos Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present this peace of code to create the baseline for the competition, and as an example of how to deal with these kind of problems. The main goals are that you:\n",
    "\n",
    "1. Learn\n",
    "2. Try different models and see which one fits the best the given data\n",
    "3. Get a higher score than the given one in the current baseline example\n",
    "4. Try to get the highest score in the class :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats \n",
    "import seaborn as sns \n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from IPython.display import display_html\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from imblearn.ensemble import BalancedBaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el dataset original\n",
    "original_df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Verificamos columnas con sus datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Averiguamos el nombre de cada variable presente en el dataset\n",
    "original_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Inspeccionamos las primeras filas del dataset\n",
    "original_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:** Contamos con 453.411 registros y 7 variables en nuestra base de datos;\n",
    "* **TripType:** Es nuestra variable objetivo. Es una identificación categórica (id) que representa el tipo de viaje de compras que realizó el clienteEsta variable no estará presente en el conjunto de test.\n",
    "* **VisitNumber:** Número de identificación del comprador o visitante.\n",
    "* **Weekday:** Día de la semana en que se hizo la compra.\n",
    "* **Upc:** Codigo de identifiación del producto, hace referencia al código de barras.\n",
    "* **ScanCount:** Cantidad de unidades de ese item que el cliente compró. El valor negativo, indica que el item se devolvió\n",
    "* **DepartmentDescription:** Es una descripción de alto nivel del departamento al que pertenece el artículo.\n",
    "* **FinelineNumber:** Hace referencia a una categoría más refinada para cada uno de los productos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Consultamos el tipo de dato de cada variable\n",
    "original_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Pedimos una descripción de los datos. Por defecto se muestra la información de las variables numéricas\n",
    "original_df.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Como tenemos variables tipo Object, pedimos ver un resumen del resto de los datos (no numéricos)\n",
    "original_df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "* La mayor compra de un item, fue de 71 unidades\n",
    "* El día más cocurrido para hacer compras es el domingo\n",
    "* Los productos más elegidos son los categorizados como **Grocery dry goods**\n",
    "* Los valores de conteo total por variable no coinciden, lo que nos habla de que hay variables con datos nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Chequeamos que no haya caracteres fuera de a-Z, 0-9 y _ en los nombres de las variables/columnas\n",
    "original_df.columns[~original_df.columns.str.match(r'^(\\w+)$')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Averiguamos los posibles valores que toman las variables tipo Object\n",
    "# Variable Weekday\n",
    "set(original_df.Weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable DepartmentDescription\n",
    "set(original_df.DepartmentDescription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Cuantificamos por Tipo de Viaje (TripType)\n",
    "s_triptype = original_df.groupby(\"VisitNumber\").TripType.mean().value_counts()\n",
    "df_triptype = s_triptype.to_frame(name=\"TripType\")\n",
    "df_triptype = df_triptype.sort_values('TripType')\n",
    "df_triptype_styler = df_triptype.style.set_table_attributes(\"style='display:inline;padding-left:20px;'\").set_caption('Cantidad por TRIPTYPE')\n",
    "display_html(df_triptype_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Agrupamos por VisitNumber para realizar un conteo de los valores de la variable TripType \n",
    "plt.figure (figsize=(8,6))\n",
    "plt.title('Cantidad de Tickets por TripType')\n",
    "sns.despine(left=True)\n",
    "original_df.groupby(\"VisitNumber\").TripType.mean().value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Observación:** Los datos se encuentran desbalanceados con respecto a la cantidad de registros por TripType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Graficamos TripType agrupado por Weekday\n",
    "plt.figure (figsize=(6,4))\n",
    "plt.title('TripType agrupado por Weekday')\n",
    "sns.countplot(data=original_df, x='Weekday', color='dodgerblue')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Quantity')\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Verificacion de Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Obtenemos el número de valores faltantes por columna(variables) \n",
    "missing_values_count = original_df.isnull().sum()\n",
    "missing_values_count[missing_values_count > 0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Chequeamos si los registros con valores nulos de DepartmentDescription, se corresponden con los de Upc y FinelineNumber\n",
    "(original_df.DepartmentDescription.isnull().sum(),\n",
    " (original_df.DepartmentDescription.isnull() & original_df.Upc.isnull() & original_df.FinelineNumber.isnull()).sum()) # si es nan el departamento los otros dos atributos lo son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Chequeamos si los registros con valores nulos de Upc, se corresponden con los de FinelineNumber\n",
    "(original_df.Upc.isnull().sum(),\n",
    " original_df.FinelineNumber.isnull().sum(),\n",
    " (original_df.FinelineNumber.isnull() & original_df.Upc.isnull()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Eliminamos los registros que tengan valores nulos para las 3 variables\n",
    "df_notna = original_df[pd.notnull(original_df['DepartmentDescription'])]\n",
    "print(df_notna.DepartmentDescription.isnull().sum())\n",
    "print(df_notna.FinelineNumber.isnull().sum())\n",
    "print(df_notna.Upc.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cantidad de Registros iniciales;\", len(original_df))\n",
    "print(\"Cantidad de registros removidos:\", len(original_df) - len(df_notna))\n",
    "print(\"Cantidad de Registros actuales:\", len(df_notna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Reemplazamos los NaN de la feature UPC por la moda ya que se trata de una variable numerica discreta\n",
    "warnings.filterwarnings('ignore')\n",
    "df_notna.Upc.mode()[0]\n",
    "\n",
    "df_notna.fillna({'Upc': df_notna.Upc.mode()[0]}, inplace=True)\n",
    "df_notna.Upc.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Reemplazamos los NaN de la feature FinelineNumber por la moda ya que se trata de una variable numerica discreta\n",
    "warnings.filterwarnings('ignore')\n",
    "df_notna.FinelineNumber.mode()[0]\n",
    "\n",
    "df_notna.fillna({'FinelineNumber': df_notna.FinelineNumber.mode()[0]}, inplace=True)\n",
    "df_notna.FinelineNumber.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:** \n",
    "* Tenemos tres variables con valores nulos (Upc, DepartmentDescription y FinelineNumber).\n",
    "* La cantidad de nulos para las variables Upc y FinelineNumber es el mismo, y los registros se corresponden.\n",
    "* Verificamos que cuando DepartmentDescription es NaN, las columnas Upc y FinelineNumber también lo son, por lo tanto removemos esos registros.\n",
    "* Reemplazamos por la moda, los valores nulos de las variables Upc y FinelineNumber."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Verificacion y eliminacion de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Graficamos los boxplot para detectar outliers\n",
    "for feature in df_notna.columns:\n",
    "    if feature != 'TripType':\n",
    "        plt.figure (figsize=(15,8))\n",
    "        sns.boxplot(data=df_notna, color='dodgerblue', x='TripType', y=feature)\n",
    "        plt.xlim(0, 50)\n",
    "        plt.ylabel(feature)\n",
    "        plt.xlabel('TripType')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "* Para la variable **VisitNumber** se detectan muy pocos outliers en los Triptype 12 y 14. Pero al ser una variable identificadora (id) no se considerarán como outliers esos valores.\n",
    "* La variable **Upc** posee muhcos outliers para la mayoría de los diferentes Triptype. \n",
    "* La variable **FinelineNumber** que también es un código de clasificación, posee menos outliers que **Upc**.\n",
    "* Podemos notar que para la variable **ScanCount** existen outliers para algunos Tipos de Viaje (TripType).\n",
    "* La variable  **DepartmentDescription** posee muchas categorías con outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Filtramos los outliers \n",
    "def clean_outliers(dataset, column_name):\n",
    "    \"\"\"Returns dataset removing the outlier rows from column @column_name.\"\"\"\n",
    "    interesting_col = dataset[column_name]\n",
    "    mask_var_outlier = (\n",
    "        np.abs(interesting_col - interesting_col.mean()) <= (15 * interesting_col.std()))\n",
    "    return dataset[mask_var_outlier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos los outliers de la variable ScanCount\n",
    "df_clean_ScanCount = clean_outliers(df_notna, \"ScanCount\")\n",
    "print(\"Filas removidas\", len(df_notna) - len(df_clean_ScanCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefiimos el nombre del dataset y calculamos el total de filas removidas hasta el momento\n",
    "df_clean = df_clean_ScanCount\n",
    "print(\"Cantidad de registros iniciales\", len(original_df))\n",
    "print(\"Total de registros filtrados\", len(original_df) - len(df_clean))\n",
    "print(\"Total de registros actuales\", len(df_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Graficamos los boxplot para corroborar la limpieza de los outliers de la variable ScanCount\n",
    "\n",
    "plt.figure (figsize=(17,6))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt1=sns.boxplot(data=original_df, color='green', x='TripType', y='ScanCount')\n",
    "plt.title('ScanCount Original')\n",
    "plt.ylabel('ScanCount')\n",
    "plt.xlabel('TripType')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt2=sns.boxplot(data=df_clean, color='green', x='TripType', y='ScanCount')\n",
    "plt.title('ScanCount Filtrado')\n",
    "plt.ylabel('ScanCount')\n",
    "plt.xlabel('TripType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Agrupamos los registros por VisitNumber\n",
    "df_group = original_df.groupby(by='VisitNumber', as_index=False).agg({'Weekday': pd.Series.nunique})\n",
    "print(df_group['Weekday'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = original_df.groupby(by='VisitNumber', as_index=False).agg({'TripType': pd.Series.nunique})\n",
    "print(df_group['TripType'].unique()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "* Al agrupar por **VisitNumber** y verificar los valores de Weekday notamos que todos los tickets son únicos para la variable Weekday\n",
    "* Indica que Cada Visitante realizó una única compra en un mismo día.\n",
    "* Al agrupar por **VisitNumber** y verificar los valores de TripType notamos tambien que todos los tickets son únicos para esta feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = df_clean.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).max().TripType\n",
    "#y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bins = set(df_clean.TripType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4  Luego del análisis exploratorio, presentamos las consideraciones importantes que tomaremos en cuenta para la creación de la función que limpie y cargue el nuevo dataset:\n",
    "* **1)** Usaremos **One hot encoding** para las variables **Weekday** y **DepartmentDescription**. Todas las transformaciones son aplicadas a los sets de Train y Test.\n",
    "* **2)** No filtraremos los valores nulos de **DepartmentDescription**.\n",
    "* **3)** Reemplazamos los valores nulos de la variable **Upc**  por la moda, ya que se trata de una variable numérica discreta.\n",
    "* **4)** Es posible que tengamos varios registros para una sola visita (VisitNumber) y el objetivo es clasificar todos esos registros exactamente de la misma manera. Por tanto, prepararemos los datos de forma que toda la información de una visita quede en el mismo registro.\n",
    "* **5)** Eliminaremos los outliers de las variables **ScanCount** con más de 15 desviaciones de la media\n",
    "* **6)** Contaremos la variable **DepartmentDescription** para todos los artículos adquiridos en la misma visita.\n",
    "* **7)** Para probar los distintos modelos tomaremos la mitad del dataset en forma aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data_fname, test_data_fname):\n",
    "    df_train = pd.read_csv(train_data_fname) # Cargamos el dataset de Entrenamiento\n",
    "    df_train['is_train_set'] = 1\n",
    "    df_test = pd.read_csv(test_data_fname) # Cargamos el dataset de Evaluación\n",
    "    df_test['is_train_set'] = 0\n",
    "   \n",
    "      # En el set de Entrenamiento\n",
    "    # Agrupamos el dataset por VisitNumber y obtenemos el máximo\n",
    "    y = df_train.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).max().TripType\n",
    "\n",
    "    # Removemos la variable TripType\n",
    "    # Unificamos los conjuntos de datos (train y test)\n",
    "    # Utilizamos la función concat para mantener el mismo índice de los registros\n",
    "    df_train = df_train.drop(\"TripType\", axis=1)\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    \n",
    "    # Reemplazamos los valores nulos de Upc y Finelinenumber\n",
    "    df.fillna({'Upc': original_df.Upc.mode()[0]}, inplace=True)\n",
    "    df.fillna({'FinelineNumber': 0}, inplace=True)\n",
    "\n",
    "    # Aplicamos one-hot encoding para la variable DepartmentDescription sin valores nulos\n",
    "    df = pd.get_dummies(df, columns=[\"DepartmentDescription\"], dummy_na=True)\n",
    "\n",
    "    # Agrupamos por visitNumber\n",
    "    df = df.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).sum()\n",
    "    \n",
    "    # Aplicamos one-hot encoding par la variable Weekday\n",
    "    df = pd.get_dummies(df, columns=[\"Weekday\"], dummy_na=True)\n",
    "\n",
    "    # Obtenemos los sets de Entrenamiento y Evaluación\n",
    "    df_train = df[df.is_train_set != 0]\n",
    "    df_test = df[df.is_train_set == 0]\n",
    "    \n",
    "    X = df_train.drop([\"is_train_set\"], axis=1)\n",
    "    yy = None\n",
    "    XX = df_test.drop([\"is_train_set\"], axis=1)\n",
    "\n",
    "    return X, y, XX, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos la información del dataset\n",
    "X, y, XX, yy = transform_data(\"../data/train.csv\", \"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape, XX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prueba de diferentes modelos para seleccionar cual ajusta mejor a nuestros datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DESBALANCEO DE DATOS**\n",
    "Podemos optar por alguno de estos dos metodos para balancearlos\n",
    "\n",
    "*Ajuste de Parámetros del modelo*: Consiste en ajustar parametros ó metricas del propio algoritmo para intentar equilibrar a la clase minoritaria penalizando a la clase mayoritaria durante el entrenamiento. Ejemplos on ajuste de peso en árboles, también en logisticregression tenemos el parámetro class_weight= “balanced” que utilizaremos en este ejemplo. No todos los algoritmos tienen estas posibilidades. En redes neuronales por ejemplo podríamos ajustar la métrica de Loss para que penalice a las clases mayoritarias.\n",
    "\n",
    "*Balanced Ensemble Methods*: Utiliza las ventajas de hacer ensamble de métodos, es decir, entrenar diversos modelos y entre todos obtener el resultado final (por ejemplo “votando”) pero se asegura de tomar muestras de entrenamiento equilibradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación y Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Selección del Modelo: **Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Dividir los dataset en entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El dataframe results será utilizado para almacenar los resultaados computados\n",
    "results = pd.DataFrame(columns=('clf', 'best_acc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Setear Hiperparametros, entrenar y seleccionar el Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteo de Hiperparametros\n",
    "rf_param = {\n",
    "              'criterion':('gini', 'entropy'), \n",
    "              'min_samples_leaf':(1, 5, 10),\n",
    "              'min_samples_split':(2, 3, 5, 10, 20, 30),\n",
    "              'random_state': [0,1,2],\n",
    "              'n_estimators': [50,75,100],\n",
    "              'class_weight' : ('balanced', 'balanced_subsample'),\n",
    "              'random_state': [0,1,2]\n",
    "            }\n",
    "\n",
    "model_rf = RandomForestClassifier()\n",
    "rf_clf = GridSearchCV(model_rf, rf_param, cv=3, scoring='accuracy') #scoring='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteamos un nuevo dataframe llamado results_rf, para almacenar los resultados computados\n",
    "results_rf = rf_clf.cv_results_\n",
    "    \n",
    "df = pd.DataFrame(results_rf\n",
    "df_result = df[['param_criterion', 'param_min_samples_leaf', 'param_min_samples_split', 'param_random_state', 'param_n_estimators', 'param_class_weight', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos el modelo con mean_test_score mas alto y menor varianza\n",
    "df_bm = df_result[df_result['rank_test_score'] == 1]\n",
    "df_bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_clf = rf_clf.best_estimator_\n",
    "bestpar = rf_clf.best_params_\n",
    "\n",
    "print('Mejor Modelo\\n', best_rf_clf)\n",
    "print('Mejores Parametros\\n', bestpar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Random Forest accuracy: ', rf_clf.best_score_)\n",
    "results = results.append({'clf': best_rf_clf, 'best_acc': rf_clf.best_score_}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos predicciones para el set de Evaluación\n",
    "X.shape, XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = results.clf.iloc[0].predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.VisitNumber, yy)), columns=[\"VisitNumber\", \"TripType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"../data/submission_4.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
